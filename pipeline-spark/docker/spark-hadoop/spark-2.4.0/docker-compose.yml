version: '3'

services:
  spark-master:
    image: spark:2.4.0
    command: bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    hostname: spark-master
    container_name: spark-master
#mem_limit: 16g
#memswap_limit: 16g
    environment:
      MASTER: spark://spark-master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_DRIVER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 8G
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.access.key: ${AWS_ACCESS_KEY_ID}
#      spark.hadoop.fs.s3a.secret.key: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    expose:
      - 465
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./shared:/tmp/shared
      - ./spark/conf/master:/conf
      - ~/.aws:/root/.aws
      
  spark-worker1:
    image: spark:2.4.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 
    hostname: spark-worker1
    container_name: spark-worker1
#mem_limit: 16g
#memswap_limit: 16g
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8181
      SPARK_PUBLIC_DNS: localhost
      SPARK_EXECUTOR_INSTANCES: 2
      SPARK_EXECUTOR_CORES: 2
      SPARK_EXECUTOR_MEMORY: 8G
      SPARK_DRIVER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 8G
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.access.key: ${AWS_ACCESS_KEY_ID}
#      spark.hadoop.fs.s3a.secret.key: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    links:
      - spark-master
    expose:
      - 465
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8181:8181
    volumes:
      - ./shared:/tmp/shared
      - ./spark/conf/worker:/conf
      - ~/.aws:/root/.aws
      
  spark-worker2:
    image: spark:2.4.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker2
    container_name: spark-worker2
#mem_limit: 16g
#memswap_limit: 16g
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8182
      SPARK_PUBLIC_DNS: localhost
      SPARK_EXECUTOR_INSTANCES: 2
      SPARK_EXECUTOR_CORES: 2
      SPARK_EXECUTOR_MEMORY: 8G
      SPARK_DRIVER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 8G
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.access.key: ${AWS_ACCESS_KEY_ID}
#      spark.hadoop.fs.s3a.secret.key: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    links:
      - spark-master
    expose:
      - 465
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8182:8182
    volumes:
      - ./shared:/tmp/shared
      - ./spark/conf/worker:/conf
      - ~/.aws:/root/.aws
     
  spark-worker3:
    image: spark:2.4.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker3
    container_name: spark-worker3
#mem_limit: 16g
#memswap_limit: 16g
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8183
      SPARK_PUBLIC_DNS: localhost
      SPARK_EXECUTOR_INSTANCES: 2
      SPARK_EXECUTOR_CORES: 2
      SPARK_EXECUTOR_MEMORY: 8G
      SPARK_DRIVER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 8G
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.access.key: ${AWS_ACCESS_KEY_ID}
#      spark.hadoop.fs.s3a.secret.key: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    links:
      - spark-master
    expose:
      - 465
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8183:8183
    volumes:
      - ./shared:/tmp/shared
      - ./spark/conf/worker:/conf
      - ~/.aws:/root/.aws
     
  spark-worker4:
    image: spark:2.4.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker4
    container_name: spark-worker4
#mem_limit: 16g
#memswap_limit: 16g
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8184
      SPARK_PUBLIC_DNS: localhost
      SPARK_EXECUTOR_INSTANCES: 2
      SPARK_EXECUTOR_CORES: 2
      SPARK_EXECUTOR_MEMORY: 8G
      SPARK_DRIVER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 8G
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.access.key: ${AWS_ACCESS_KEY_ID}
#      spark.hadoop.fs.s3a.secret.key: ${AWS_SECRET_ACCESS_KEY}
#      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    links:
      - spark-master
    expose:
      - 465
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8184:8184
    volumes:
      - ./shared:/tmp/shared
      - ./spark/conf/worker:/conf
      - ~/.aws:/root/.aws

